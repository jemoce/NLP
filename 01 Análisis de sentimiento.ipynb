{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 02 - Your first NLP application.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW0jTBQbVL54",
        "outputId": "b50a121c-0c7b-4245-802d-ea1f21faecb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 103 kB 13.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 804.1 MB 2.7 kB/s \n",
            "\u001b[K     |████████████████████████████████| 124 kB 43.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 34.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 32.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 8.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 167 kB 47.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 37.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 51.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 54.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 42.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 47.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 143 kB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 23.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 39.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 419 kB 47.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 104 kB 45.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 41.8 MB/s \n",
            "\u001b[?25h  Building wheel for checklist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for patternfork-nosql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.8.1 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 1.3.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.4 MB/s \n",
            "\u001b[?25h  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q allennlp==2.5.0\n",
        "!pip install -q allennlp-models==2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mhagiwara/realworldnlp.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHNc7X3pbMuU",
        "outputId": "019e0d61-2bfa-4dc4-d098-b40b9d355a47"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'realworldnlp'...\n",
            "remote: Enumerating objects: 668, done.\u001b[K\n",
            "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 668 (delta 119), reused 116 (delta 52), pack-reused 479\u001b[K\n",
            "Receiving objects: 100% (668/668), 4.95 MiB | 10.81 MiB/s, done.\n",
            "Resolving deltas: 100% (370/370), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnKyH0Zlbf7S",
        "outputId": "1c6be5b5-54a1-46d7-f95d-c622b7a28b56"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "from typing import Dict\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from allennlp.data.data_loaders import MultiProcessDataLoader\n",
        "from allennlp.data.samplers import BucketBatchSampler\n",
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.data.tokenizers.spacy_tokenizer import SpacyTokenizer\n",
        "from allennlp.models import Model\n",
        "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
        "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import Embedding\n",
        "from allennlp.nn.util import get_text_field_mask\n",
        "from allennlp.training import GradientDescentTrainer\n",
        "from allennlp.training.metrics import CategoricalAccuracy, F1Measure\n",
        "from allennlp_models.classification.dataset_readers.stanford_sentiment_tree_bank import StanfordSentimentTreeBankDatasetReader\n",
        "from realworldnlp.realworldnlp.predictors import SentenceClassifierPredictor"
      ],
      "metadata": {
        "id": "3O3-FfFmVR0n"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 128"
      ],
      "metadata": {
        "id": "pQLC1oQ5XU90"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LstmClassifier(Model):\n",
        "  def __init__(self,\n",
        "               embedder: TextFieldEmbedder,\n",
        "               encoder: Seq2VecEncoder,\n",
        "               vocab: Vocabulary,\n",
        "               positive_label: str = '4') -> None:\n",
        "    super().__init__(vocab)\n",
        "    self.embedder = embedder\n",
        "    self.encoder = encoder\n",
        "    self.linear = torch.nn.Linear(in_features=encoder.get_output_dim(), out_features=vocab.get_vocab_size('labels'))\n",
        "\n",
        "    positive_index = vocab.get_token_index(positive_label, namespace='labels')\n",
        "    self.accuracy = CategoricalAccuracy()\n",
        "    self.f1_measure = F1Measure(positive_index)                            \n",
        "    self.loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self,\n",
        "              tokens: Dict[str, torch.Tensor],\n",
        "              label: torch.Tensor = None) -> torch.Tensor:\n",
        "    mask = get_text_field_mask(tokens)\n",
        "    embeddings = self.embedder(tokens)\n",
        "    encoder_out = self.encoder(embeddings, mask)\n",
        "    logits = self.linear(encoder_out)\n",
        "\n",
        "    output = {'logits':logits}\n",
        "    if label is not None:\n",
        "      self.accuracy(logits, label)\n",
        "      self.f1_measure(logits, label)\n",
        "      output['loss'] = self.loss_function(logits, label)\n",
        "\n",
        "    return output\n",
        "\n",
        "  def get_metrics(self, reset:bool = False) -> Dict[str, float]:\n",
        "    return {'accuracy': self.accuracy.get_metric(reset), **self.f1_measure.get_metric(reset)}"
      ],
      "metadata": {
        "id": "j006OZSe_7P_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip'\n",
        "\n",
        "zip_path, _ = urllib.request.urlretrieve(url)\n",
        "with zipfile.ZipFile(zip_path, \"r\") as f:\n",
        "    f.extractall()"
      ],
      "metadata": {
        "id": "F5qeQrjXViH8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = StanfordSentimentTreeBankDatasetReader()\n",
        "data_path = r'./trees'\n",
        "train_file = 'train.txt'\n",
        "test_file = 'test.txt'\n",
        "dev_file = 'dev.txt'\n",
        "\n",
        "train_path = os.path.join(data_path, train_file)\n",
        "dev_path = os.path.join(data_path, dev_file)"
      ],
      "metadata": {
        "id": "3HmSRU5XW7n-"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = StanfordSentimentTreeBankDatasetReader()\n",
        "train_path = 'https://s3.amazonaws.com/realworldnlpbook/data/stanfordSentimentTreebank/trees/train.txt'\n",
        "dev_path = 'https://s3.amazonaws.com/realworldnlpbook/data/stanfordSentimentTreebank/trees/dev.txt'"
      ],
      "metadata": {
        "id": "Xbua-jWlgLHs"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = BucketBatchSampler(batch_size=32, sorting_keys=['tokens'])\n",
        "train_data_loader = MultiProcessDataLoader(reader, train_path, batch_sampler=sampler)\n",
        "dev_data_loader = MultiProcessDataLoader(reader, dev_path, batch_sampler=sampler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pdudeq-1YQkH",
        "outputId": "da43b407-cd8f-4b9c-e797-8297eb2c8619"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading instances: 8544it [00:01, 4320.58it/s]\n",
            "loading instances: 1101it [00:00, 1888.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Vocabulary.from_instances(\n",
        "    chain(\n",
        "        train_data_loader.iter_instances(),\n",
        "        dev_data_loader.iter_instances()\n",
        "    ),\n",
        "    min_count={'tokens':3}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBVedk1GG__U",
        "outputId": "82fef622-3f10-4c88-e8af-cb780934ae02"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "building vocab: 9645it [00:00, 47965.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader.index_with(vocab)\n",
        "dev_data_loader.index_with(vocab)"
      ],
      "metadata": {
        "id": "KopeqHePHK9Q"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'), embedding_dim=EMBEDDING_DIM)\n",
        "word_embeddings = BasicTextFieldEmbedder({'tokens': token_embedding})"
      ],
      "metadata": {
        "id": "Pa3QPcMTHK2p"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = PytorchSeq2VecWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
        "model = LstmClassifier(embedder=word_embeddings, \n",
        "                       encoder=encoder, \n",
        "                       vocab=vocab, \n",
        "                       positive_label='4')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "nwc_WMtN5I2e"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = GradientDescentTrainer(\n",
        "    model = model,\n",
        "    optimizer=optimizer,\n",
        "    data_loader=train_data_loader,\n",
        "    validation_data_loader=dev_data_loader,\n",
        "    patience=10,\n",
        "    num_epochs=20,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHbk_yK6ImFw",
        "outputId": "975ac580-11ae-4dec-bf38-319aa0299d57"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "accuracy: 0.2603, precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 1.6158, loss: 1.5835 ||: 100%|##########| 267/267 [00:03<00:00, 73.13it/s]\n",
            "accuracy: 0.2534, precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 1.6235, loss: 1.5740 ||: 100%|##########| 35/35 [00:00<00:00, 145.70it/s]\n",
            "accuracy: 0.2726, precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 1.6199, loss: 1.5651 ||: 100%|##########| 267/267 [00:03<00:00, 77.25it/s]\n",
            "accuracy: 0.2652, precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 1.5839, loss: 1.5714 ||: 100%|##########| 35/35 [00:00<00:00, 151.23it/s]\n",
            "accuracy: 0.2808, precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 1.5079, loss: 1.5556 ||: 100%|##########| 267/267 [00:03<00:00, 76.86it/s]\n",
            "accuracy: 0.2552, precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 1.5743, loss: 1.5677 ||: 100%|##########| 35/35 [00:00<00:00, 150.94it/s]\n",
            "accuracy: 0.2952, precision: 0.4706, recall: 0.0062, f1: 0.0123, batch_loss: 1.5487, loss: 1.5214 ||: 100%|##########| 267/267 [00:03<00:00, 77.02it/s]\n",
            "accuracy: 0.2816, precision: 0.2308, recall: 0.0182, f1: 0.0337, batch_loss: 1.6001, loss: 1.5537 ||: 100%|##########| 35/35 [00:00<00:00, 151.40it/s]\n",
            "accuracy: 0.3476, precision: 0.4936, recall: 0.3587, f1: 0.4155, batch_loss: 1.4142, loss: 1.4505 ||: 100%|##########| 267/267 [00:03<00:00, 78.45it/s]\n",
            "accuracy: 0.3006, precision: 0.2909, recall: 0.3879, f1: 0.3325, batch_loss: 1.4065, loss: 1.5335 ||: 100%|##########| 35/35 [00:00<00:00, 148.05it/s]\n",
            "accuracy: 0.4150, precision: 0.4598, recall: 0.6747, f1: 0.5469, batch_loss: 1.1931, loss: 1.3404 ||: 100%|##########| 267/267 [00:03<00:00, 70.42it/s]\n",
            "accuracy: 0.3361, precision: 0.3275, recall: 0.4545, f1: 0.3807, batch_loss: 1.7078, loss: 1.5495 ||: 100%|##########| 35/35 [00:00<00:00, 153.45it/s]\n",
            "accuracy: 0.4828, precision: 0.5266, recall: 0.7609, f1: 0.6224, batch_loss: 1.2823, loss: 1.2254 ||: 100%|##########| 267/267 [00:03<00:00, 77.76it/s]\n",
            "accuracy: 0.3533, precision: 0.3306, recall: 0.4848, f1: 0.3931, batch_loss: 1.4428, loss: 1.4907 ||: 100%|##########| 35/35 [00:00<00:00, 156.49it/s]\n",
            "accuracy: 0.5435, precision: 0.5959, recall: 0.7842, f1: 0.6772, batch_loss: 0.8217, loss: 1.1093 ||: 100%|##########| 267/267 [00:03<00:00, 78.83it/s]\n",
            "accuracy: 0.3751, precision: 0.3731, recall: 0.4545, f1: 0.4098, batch_loss: 1.4248, loss: 1.5422 ||: 100%|##########| 35/35 [00:00<00:00, 150.98it/s]\n",
            "accuracy: 0.6018, precision: 0.6831, recall: 0.8199, f1: 0.7452, batch_loss: 0.9472, loss: 0.9883 ||: 100%|##########| 267/267 [00:03<00:00, 78.42it/s]\n",
            "accuracy: 0.3597, precision: 0.3587, recall: 0.4000, f1: 0.3782, batch_loss: 1.2927, loss: 1.5855 ||: 100%|##########| 35/35 [00:00<00:00, 157.64it/s]\n",
            "accuracy: 0.6378, precision: 0.7302, recall: 0.8323, f1: 0.7779, batch_loss: 0.9515, loss: 0.9006 ||: 100%|##########| 267/267 [00:03<00:00, 77.60it/s]\n",
            "accuracy: 0.3651, precision: 0.4222, recall: 0.3455, f1: 0.3800, batch_loss: 1.5943, loss: 1.7572 ||: 100%|##########| 35/35 [00:00<00:00, 162.31it/s]\n",
            "accuracy: 0.6746, precision: 0.7728, recall: 0.8502, f1: 0.8096, batch_loss: 0.5977, loss: 0.8168 ||: 100%|##########| 267/267 [00:03<00:00, 77.63it/s]\n",
            "accuracy: 0.3442, precision: 0.3714, recall: 0.3939, f1: 0.3824, batch_loss: 1.3630, loss: 1.7859 ||: 100%|##########| 35/35 [00:00<00:00, 145.73it/s]\n",
            "accuracy: 0.7065, precision: 0.8091, recall: 0.8657, f1: 0.8365, batch_loss: 0.7904, loss: 0.7475 ||: 100%|##########| 267/267 [00:03<00:00, 77.68it/s]\n",
            "accuracy: 0.3361, precision: 0.3736, recall: 0.3939, f1: 0.3835, batch_loss: 2.4607, loss: 1.8508 ||: 100%|##########| 35/35 [00:00<00:00, 155.19it/s]\n",
            "accuracy: 0.7233, precision: 0.8186, recall: 0.8727, f1: 0.8448, batch_loss: 0.5013, loss: 0.7039 ||: 100%|##########| 267/267 [00:03<00:00, 72.16it/s]\n",
            "accuracy: 0.3615, precision: 0.3696, recall: 0.4121, f1: 0.3897, batch_loss: 1.5314, loss: 1.9723 ||: 100%|##########| 35/35 [00:00<00:00, 155.89it/s]\n",
            "accuracy: 0.7463, precision: 0.8221, recall: 0.8719, f1: 0.8463, batch_loss: 1.2361, loss: 0.6537 ||: 100%|##########| 267/267 [00:03<00:00, 77.95it/s]\n",
            "accuracy: 0.3597, precision: 0.3987, recall: 0.3818, f1: 0.3901, batch_loss: 2.7179, loss: 2.0543 ||: 100%|##########| 35/35 [00:00<00:00, 158.13it/s]\n",
            "accuracy: 0.7679, precision: 0.8467, recall: 0.8921, f1: 0.8688, batch_loss: 0.4351, loss: 0.6094 ||: 100%|##########| 267/267 [00:03<00:00, 77.53it/s]\n",
            "accuracy: 0.3460, precision: 0.3547, recall: 0.4364, f1: 0.3913, batch_loss: 1.5495, loss: 2.1607 ||: 100%|##########| 35/35 [00:00<00:00, 152.30it/s]\n",
            "accuracy: 0.7904, precision: 0.8534, recall: 0.9084, f1: 0.8800, batch_loss: 0.2348, loss: 0.5641 ||: 100%|##########| 267/267 [00:03<00:00, 78.33it/s]\n",
            "accuracy: 0.3524, precision: 0.3669, recall: 0.3758, f1: 0.3713, batch_loss: 2.5307, loss: 2.3818 ||: 100%|##########| 35/35 [00:00<00:00, 143.72it/s]\n",
            "accuracy: 0.7972, precision: 0.8544, recall: 0.9115, f1: 0.8820, batch_loss: 0.6832, loss: 0.5498 ||: 100%|##########| 267/267 [00:03<00:00, 77.45it/s]\n",
            "accuracy: 0.3560, precision: 0.3815, recall: 0.4000, f1: 0.3905, batch_loss: 2.5806, loss: 2.3424 ||: 100%|##########| 35/35 [00:00<00:00, 156.36it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 6,\n",
              " 'best_validation_accuracy': 0.3533151680290645,\n",
              " 'best_validation_f1': 0.3931204080581665,\n",
              " 'best_validation_loss': 1.4907133204596383,\n",
              " 'best_validation_precision': 0.3305785059928894,\n",
              " 'best_validation_recall': 0.4848484992980957,\n",
              " 'epoch': 16,\n",
              " 'peak_gpu_0_memory_MB': 38.533203125,\n",
              " 'peak_worker_0_memory_MB': 2488.27734375,\n",
              " 'training_accuracy': 0.7971676029962547,\n",
              " 'training_duration': '0:01:03.383364',\n",
              " 'training_f1': 0.8820435404777527,\n",
              " 'training_gpu_0_memory_MB': 38.533203125,\n",
              " 'training_loss': 0.5498426571655809,\n",
              " 'training_precision': 0.8544396162033081,\n",
              " 'training_recall': 0.9114906787872314,\n",
              " 'training_worker_0_memory_MB': 2488.27734375,\n",
              " 'validation_accuracy': 0.35603996366939145,\n",
              " 'validation_f1': 0.39053255319595337,\n",
              " 'validation_loss': 2.3423965692520143,\n",
              " 'validation_precision': 0.3815028965473175,\n",
              " 'validation_recall': 0.4000000059604645}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels are:\n",
        "# 0: very negative\n",
        "# 1: negative\n",
        "# 2: neutral\n",
        "# 3: positive\n",
        "# 4: very positive\n",
        "\n",
        "def predict_label(sentence: str) -> int:\n",
        "  predictor = SentenceClassifierPredictor(model, reader)\n",
        "  logits = predictor.predict(sentence)['logits']\n",
        "  label_id = np.argmax(logits)\n",
        "\n",
        "  return vocab.get_token_from_index(label_id, 'labels')\n",
        "  \n",
        "to_predict = 'This is the best movie ever'\n",
        "print(f'Label is: {predict_label(to_predict)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3A0BeE0M4cj",
        "outputId": "f4cf97b7-0bed-4ed1-f818-4fd1a44eb803"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label is: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E1K0Np1rhwmc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}